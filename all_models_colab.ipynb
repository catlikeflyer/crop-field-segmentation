{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, shutil, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./deepglobe-land-cover-classification-dataset/train\"\n",
    "COLOR_CODES = \"./deepglobe-land-cover-classification-dataset/class_dict.csv\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "])\n",
    "\n",
    "df = pd.read_csv(COLOR_CODES)\n",
    "label_map = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    label_map[index] = [row[\"r\"],row[\"g\"],row[\"b\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation_Dataset(Dataset):\n",
    "    def __init__(self, image_dir, label_map, transform):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.images_name = sorted([filename for filename in os.listdir(self.image_dir) if filename.endswith('_sat.jpg') and not filename.startswith(\"._\")])\n",
    "        self.targets_name = sorted([filename for filename in os.listdir(self.image_dir) if filename.endswith('_mask.png') and not filename.startswith(\"._\")])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.images_name[idx])\n",
    "        mask_path = os.path.join(self.image_dir, self.targets_name[idx])\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(mask_path)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = self.colormap_to_labelmap(mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "            \n",
    "        return {\"image\": image, \"mask\": mask}\n",
    "    \n",
    "    def colormap_to_labelmap(self, mask):\n",
    "        label_image = np.zeros_like(mask[:,:,0], dtype=np.uint8)\n",
    "\n",
    "        for label, color in self.label_map.items():\n",
    "            color_array = np.array(color)\n",
    "            mask_condition = np.all(mask == color_array, axis=-1)\n",
    "            label_image[mask_condition] = label\n",
    "\n",
    "        return label_image.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "big_dataset = Segmentation_Dataset(TRAIN_DIR, label_map, transform)\n",
    "[train_dataset, val_dataset, test_dataset] = torch.utils.data.random_split(big_dataset,[0.75,0.15,0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCreate(L.LightningModule):\n",
    "\n",
    "    def __init__(self, arch, encoder_name, encoder_weights, in_channels, out_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = smp.create_model(arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, encoder_weights=encoder_weights)\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.fn = None\n",
    "        self.tn = None\n",
    "\n",
    "        self.losses = {\n",
    "            'valid': [],\n",
    "            'train': [],\n",
    "            'test': []\n",
    "        }\n",
    "\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name, encoder_weights)\n",
    "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
    "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
    "\n",
    "        self.loss_fn = smp.losses.DiceLoss(smp.losses.MULTICLASS_MODE, from_logits=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n",
    "\n",
    "    def shared_step(self, batch, stage):\n",
    "\n",
    "        image = batch[\"image\"]\n",
    "\n",
    "        assert image.ndim == 4\n",
    "\n",
    "        h, w = image.shape[2:]\n",
    "        assert h % 32 == 0 and w % 32 == 0\n",
    "\n",
    "        mask = batch[\"mask\"]\n",
    "\n",
    "        assert mask.ndim == 4\n",
    "\n",
    "        assert mask.max() <= 7 and mask.min() >= 0\n",
    "\n",
    "        logits_mask = self.forward(image)\n",
    "\n",
    "        loss = self.loss_fn(logits_mask, mask)\n",
    "\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), prob_mask.long(), num_classes=7, mode=\"multiclass\")\n",
    "\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.tn = tn\n",
    "        self.fn = fn\n",
    "\n",
    "        self.losses[stage].append(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def shared_epoch_end(self, stage):\n",
    "        tp = self.tp\n",
    "        fp = self.fp\n",
    "        fn = self.fn\n",
    "        tn = self.tn\n",
    "\n",
    "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "\n",
    "        metrics = {\n",
    "            f\"{stage}_loss\": torch.stack(self.losses[stage]).mean(),\n",
    "            f\"{stage}_per_image_iou\": per_image_iou,\n",
    "            f\"{stage}_dataset_iou\": dataset_iou,\n",
    "        }\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True, logger=True)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        return self.shared_step(batch, \"train\")\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"train\")\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        return self.shared_step(batch, \"valid\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"valid\")\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        return self.shared_step(batch, \"test\")\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        return self.shared_epoch_end(\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelCreate(\"UnetPlusPlus\", \"resnet50\", 'imagenet', in_channels=3, out_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/unetpp\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | model   | UnetPlusPlus | 49.0 M\n",
      "1 | loss_fn | DiceLoss     | 0     \n",
      "-----------------------------------------\n",
      "49.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "49.0 M    Total params\n",
      "195.946   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba6a2e40b8a45b2bd57bc5035fb84a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c7f65f628947d8b16055354c898ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68a4eb3513046e98b7d38d350c5b719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b00eed34811400db9ec098adf3c03a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a33a4f110440de82eeac3705cedec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping('valid_loss', patience=3)\n",
    "\n",
    "#trainer = L.Trainer(max_epochs=15, logger=CSVLogger(save_dir=\"logs/\", name=\"unetpp\"), callbacks=[earlystop_callback])\n",
    "\n",
    "# Apple Silicon\n",
    "trainer = L.Trainer(accelerator=\"mps\" ,max_epochs=15, logger=CSVLogger(save_dir=\"logs/\", name=\"unetpp\"), callbacks=[earlystop_callback])\n",
    "\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics = trainer.validate(model, dataloaders=valid_dataloader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.test(model, dataloaders=test_dataloader, verbose=False)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metrics.csv file generated by the PyTorch Lightning logger\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "\n",
    "# Group the metrics by epoch and compute the mean loss for each epoch\n",
    "df_epochs = metrics.groupby('epoch').mean()\n",
    "\n",
    "display(df_epochs)\n",
    "\n",
    "# Create a figure and axis for plotting\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Epochs')\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Loss')\n",
    "ax.plot(df_epochs['train_loss'], label=\"Training loss\")\n",
    "ax.plot(df_epochs['valid_loss'], label=\"Validation loss\")\n",
    "\n",
    "ax.plot(df_epochs['train_dataset_iou'], label=\"Training Dataset IoU\")\n",
    "ax.plot(df_epochs['valid_dataset_iou'], label=\"Validation Dataset IoU\")\n",
    "\n",
    "# Plot the training loss over epochs\n",
    "# Plot the validation loss over epochs\n",
    "# Set the title of the plot\n",
    "ax.set_title(\"Training Loss\")\n",
    "# Add a legend to the plot\n",
    "ax.legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
